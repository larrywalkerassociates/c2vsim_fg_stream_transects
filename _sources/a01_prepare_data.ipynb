{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f25895",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from shapely import LineString, Point\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from iwfm_lwa import (skip_until_flag, get_groundwater_nodes, load_gwalloutfl, get_stratigraphy, get_stream_nodes,\n",
    "                      get_var, line_to_list)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Path to the root of the repository\n",
    "repo_dir = os.getcwd()\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "while os.path.split(os.path.split(repo_dir)[0])[1] == \"c2vsim_fg_stream_transects\":\n",
    "    repo_dir = os.path.split(repo_dir)[0]\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "from functions.make_stream_lines_gdf import make_stream_lines_gdf\n",
    "from functions.project_points_gdf_to_line_string import project_points_gdf_to_line_string\n",
    "\n",
    "os.chdir(current_dir)\n",
    "\n",
    "# Let's set key paths\n",
    "data_dir = os.path.join(repo_dir, \"data\")\n",
    "model_dir = os.path.join(data_dir, \"c2vsimfg_v1.5\")\n",
    "preprocessor_dir = os.path.join(model_dir, \"Preprocessor\")\n",
    "results_dir = os.path.join(model_dir, \"Results\")\n",
    "aem_dir = os.path.join(data_dir, \"sa7_supportingdata_20230428\")\n",
    "\n",
    "gwalloutfl_path = os.path.join(results_dir, \"C2VSimFG_GW_HeadAll.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4e39b",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# Preparing Stream and Groundwater Data from C2VSimFG v1.5\n",
    "In this section, we prepare the model data that will be used to make the stream transects. The workflow used hereafter\n",
    "consists of the following steps:\n",
    "1. We load the Stream Specification File and the Nodal X-Y Coordinate File and generate a lines geodataframe\n",
    "of the streams represented in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba029e5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let's create the geodataframe of streams\n",
    "\n",
    "# Path to stream definition file\n",
    "streams_def_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_StreamsSpec.dat\")\n",
    "\n",
    "# Path to node definition file\n",
    "nodes_def_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_Nodes.dat\")\n",
    "\n",
    "stream_lines_shp_path = os.path.join(data_dir, \"stream_lines.shp\")\n",
    "\n",
    "stream_nodes_df = get_stream_nodes(streams_def_file_path, rating_points=10)\n",
    "\n",
    "# We'll have to import the node definition file\n",
    "gw_nodes_df = get_groundwater_nodes(nodes_def_file_path)\n",
    "\n",
    "make_stream_lines_shp = True\n",
    "\n",
    "if make_stream_lines_shp:\n",
    "\n",
    "    streams_gdf = make_stream_lines_gdf(stream_nodes_df, gw_nodes_df)\n",
    "    streams_gdf.to_file(stream_lines_shp_path)\n",
    "\n",
    "else:\n",
    "    streams_gdf = gpd.read_file(stream_lines_shp_path)\n",
    "\n",
    "butte_creek_line_gdf = streams_gdf.loc[streams_gdf[\"name\"].str.find(\"BUTTE\")>=0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de513bf",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "2. Using the stream lines shapefile generated in the previous step, we calculate the distance of each stream node with\n",
    "respect to the origin of the stream line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9705735",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Let's add stream coordinates to stream nodes\n",
    "stream_nodes_df = pd.merge(stream_nodes_df, gw_nodes_df, on=\"igw\", how=\"left\")\n",
    "\n",
    "records = []\n",
    "stream_line = list(streams_gdf.itertuples())[0]\n",
    "for stream_line in streams_gdf.itertuples():\n",
    "    stream_line_geometry = getattr(stream_line, \"geometry\")\n",
    "    stream_name = getattr(stream_line, \"name\")\n",
    "    for stream_node in stream_nodes_df[stream_nodes_df[\"name\"] == stream_name].reset_index(drop=True).itertuples():\n",
    "        stream_node_x = getattr(stream_node, \"x\")\n",
    "        stream_node_y = getattr(stream_node, \"y\")\n",
    "        irv = getattr(stream_node, \"irv\")\n",
    "        point = Point(stream_node_x, stream_node_y)\n",
    "        proj = stream_line_geometry.project(point)\n",
    "        record = {\n",
    "            \"irv\": irv,\n",
    "            \"proj\": proj\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "projs_df = pd.DataFrame(records)\n",
    "stream_nodes_df = pd.merge(stream_nodes_df, projs_df, how=\"left\")\n",
    "\n",
    "save_butte_creek_stream_nodes = False\n",
    "butte_creek_stream_nodes_csv_path = os.path.join(data_dir, \"butte_creek_stream_nodes.csv\")\n",
    "if save_butte_creek_stream_nodes:\n",
    "    butte_creek_stream_nodes_df = stream_nodes_df.loc[stream_nodes_df[\"name\"].str.find(\"BUTTE\")>=0].reset_index(drop=True)\n",
    "    butte_creek_stream_nodes_df.to_csv(butte_creek_stream_nodes_csv_path, index=False)\n",
    "else:\n",
    "    butte_creek_stream_nodes_df = pd.read_csv(butte_creek_stream_nodes_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0226d",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "3. We load the Stratigraphy File and join ground surface elevations and layer thicknesses to the stream nodes.\n",
    "4. We load the timeseries \"Groundwater Head at All Nodes\" file (C2VSimFG_GW_HeadAll.out) and join simulated groundwater heads\n",
    "to stream nodes.\n",
    "5. For each node, we extract the groundwater heads for the highest active layer. To do so, we iterate through the\n",
    "layers and select the highest one that presents a thickness greater than zero and is above the bottom of the layer.\n",
    "6. Select CASGEM wells and lithology logs within 500 m of Butte Creek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f41626",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Let's load stratigraphy file into dataframe\n",
    "stratigraphy_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_Stratigraphy.dat\")\n",
    "\n",
    "\n",
    "stratigraphy_df = get_stratigraphy(stratigraphy_file_path)\n",
    "\n",
    "wt_stream_nodes_csv_path = os.path.join(results_dir, \"gwallout_stream_nodes.csv\")\n",
    "butte_creek_wt_stream_nodes_csv_path = os.path.join(data_dir, \"butte_creek_gwallout_stream_nodes.csv\")\n",
    "\n",
    "make_wt_stream_nodes = False\n",
    "if make_wt_stream_nodes:\n",
    "\n",
    "    gwallout_df = load_gwalloutfl(gwalloutfl_path)\n",
    "    # Let's convert heads from m to ft\n",
    "\n",
    "    gwallout_df_long = pd.melt(gwallout_df, id_vars=[\"date\", \"layer\"], var_name=\"igw\", value_name=\"head_ft\")\n",
    "\n",
    "    # Let's add bottom elevations of layers\n",
    "    stratigraphy_df[\"botm_lay_1\"] = stratigraphy_df[\"gse\"] - stratigraphy_df[\"thck_lay_1\"]\n",
    "\n",
    "    nlay = 4\n",
    "\n",
    "    for lay in range(2, nlay+1):\n",
    "        stratigraphy_df[f\"botm_lay_{lay}\"] = stratigraphy_df[f\"botm_lay_{lay-1}\"] - stratigraphy_df[f\"thck_lay_{lay}\"]\n",
    "\n",
    "    gwallout_df_wide = pd.pivot(gwallout_df_long,index=[\"date\", \"igw\"], columns=[\"layer\"], values=[\"head_ft\"])\n",
    "\n",
    "    gwallout_df_wide = gwallout_df_wide.reset_index()\n",
    "\n",
    "    colnames = gwallout_df_wide.columns\n",
    "\n",
    "    colnames = [name[0]+\"_\"+str(name[1]) if len(str(name[1]))>0 else name[0] for name in colnames ]\n",
    "\n",
    "    gwallout_df_wide.columns = colnames\n",
    "\n",
    "    gwallout_df_wide = pd.merge(\n",
    "        gwallout_df_wide,\n",
    "    stratigraphy_df[\n",
    "        [\n",
    "            \"igw\", \"gse\"\n",
    "        ] + [\n",
    "            col for col in stratigraphy_df.columns if \"botm\" in col\n",
    "        ] + [\n",
    "            col for col in stratigraphy_df.columns if \"thck_lay\" in col\n",
    "        ]\n",
    "    ],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    def get_wte(x):\n",
    "        gse = x[\"gse\"]\n",
    "        wte = x[\"head_ft_1\"]\n",
    "        lay = 1\n",
    "        botm = x[\"botm_lay_1\"]\n",
    "        thck = x[\"thck_lay_1\"]\n",
    "        while ((\n",
    "                wte >= gse\n",
    "        ) | (\n",
    "                wte <= botm\n",
    "        ) | (\n",
    "                thck == 0\n",
    "        ))& (\n",
    "            lay < nlay\n",
    "        ):\n",
    "            lay = lay+1\n",
    "            wte = x[f\"head_ft_{lay}\"]\n",
    "            botm = x[f\"botm_lay_{lay}\"]\n",
    "            thck = x[f\"thck_lay_{lay}\"]\n",
    "        return wte\n",
    "\n",
    "    gwallout_stream_nodes_df = pd.merge(\n",
    "        gwallout_df_wide,\n",
    "        stream_nodes_df[\"igw\"],\n",
    "        how=\"right\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    gwallout_stream_nodes_df[\"wte_ft\"] = gwallout_stream_nodes_df.apply(get_wte, axis=1)\n",
    "\n",
    "    gwallout_stream_nodes_df = gwallout_stream_nodes_df[\n",
    "        [\"date\", \"igw\", \"wte_ft\", \"head_ft_1\", \"head_ft_2\", \"head_ft_2\", \"head_ft_3\", \"head_ft_4\"]\n",
    "    ]\n",
    "\n",
    "    gwallout_stream_nodes_df.to_csv(wt_stream_nodes_csv_path, index=False)\n",
    "    butte_creek_gwallout_stream_nodes_df = pd.merge(\n",
    "        gwallout_stream_nodes_df,\n",
    "        butte_creek_stream_nodes_df[\"igw\"],\n",
    "\n",
    "        how=\"right\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    butte_creek_gwallout_stream_nodes_df.to_csv(butte_creek_wt_stream_nodes_csv_path, index=False)\n",
    "else:\n",
    "    gwallout_stream_nodes_df = pd.read_csv(wt_stream_nodes_csv_path)\n",
    "    butte_creek_gwallout_stream_nodes_df = pd.read_csv(butte_creek_wt_stream_nodes_csv_path)\n",
    "\n",
    "all_ts_df = pd.DataFrame(\n",
    "    {\"date\": pd.to_datetime(gwallout_stream_nodes_df[\"date\"].unique())}\n",
    "\n",
    ")\n",
    "\n",
    "all_ts_df[\"date_sim\"] = all_ts_df[\"date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd247ed5",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "6. Select CASGEM wells and AEM lithology logs within 500 m of Butte Creek\n",
    "7. Download CASGEM water level observations for the selected wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ffd0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "butte_creek_buffer = butte_creek_line_gdf.buffer(500)[0]\n",
    "obs_wells_butte_creek_shp_path = os.path.join(data_dir, \"obs_wells_butte_creek.shp\")\n",
    "lith_logs_butte_creek_shp_path = os.path.join(data_dir, \"lith_logs_butte_creek.shp\")\n",
    "obs_butte_creek_csv_path = os.path.join(data_dir, \"obs_wells_butte_creek.csv\")\n",
    "\n",
    "select_casgem_wells_and_lithology_logs = False\n",
    "if select_casgem_wells_and_lithology_logs:\n",
    "    # We download CASGEM wells for the counties that Butte Creek crosses\n",
    "    url = \"https://data.cnra.ca.gov/api/3/action/datastore_search_sql?\"\n",
    "    records = []\n",
    "    for county in ['Butte', 'Sutter', 'Glenn', 'Tehama']:\n",
    "        sql_county = f'''sql=SELECT * from \"af157380-fb42-4abf-b72a-6f9f98868077\" WHERE \"county_name\" IN ('{county}')'''\n",
    "        sql_county = sql_county.replace(\" \", \"%20\")\n",
    "        sql_county = sql_county.replace('\"', \"%22\")\n",
    "        response_dmc = requests.get(url, params=sql_county)\n",
    "\n",
    "        response_dict = json.loads(response_dmc.text)\n",
    "        records += response_dict[\"result\"][\"records\"]\n",
    "\n",
    "    obs_wells_df = pd.json_normalize(records)\n",
    "    def add_geom_points(x):\n",
    "        geometry = Point(x[\"longitude\"], x[\"latitude\"])\n",
    "        return geometry\n",
    "\n",
    "    obs_wells_df[\"geometry\"] = obs_wells_df.apply(add_geom_points, axis=1)\n",
    "    obs_wells_gdf = gpd.GeoDataFrame(obs_wells_df, geometry=obs_wells_df.geometry, crs=4326)\n",
    "\n",
    "    obs_wells_gdf = obs_wells_gdf.to_crs(streams_gdf.crs)\n",
    "\n",
    "    obs_wells_butte_creek_gdf = obs_wells_gdf.loc[obs_wells_gdf.geometry.within(butte_creek_buffer)].reset_index(drop=True)\n",
    "\n",
    "    # Let's project the wells to the Butte Creek line\n",
    "    obs_wells_butte_creek_gdf = project_points_gdf_to_line_string(\n",
    "        obs_wells_butte_creek_gdf,\n",
    "        butte_creek_line_gdf.loc[0,\"geometry\"],\n",
    "    \"site_code\"\n",
    "    )\n",
    "\n",
    "    obs_wells_butte_creek_gdf.to_file(obs_wells_butte_creek_shp_path)\n",
    "\n",
    "    lith_logs_shp_path = os.path.join(aem_dir, \"WO7_HQ_LithologyWells.shp\")\n",
    "\n",
    "    lith_logs_gdf = gpd.read_file(lith_logs_shp_path)\n",
    "    lith_logs_gdf = lith_logs_gdf.to_crs(streams_gdf.crs)\n",
    "\n",
    "    lith_logs_butte_creek_gdf = lith_logs_gdf.loc[lith_logs_gdf.geometry.within(butte_creek_buffer)].reset_index(drop=True)\n",
    "\n",
    "    # Let's project the lithology logs to the Butte Creek line\n",
    "    lith_logs_butte_creek_gdf = project_points_gdf_to_line_string(\n",
    "        lith_logs_butte_creek_gdf,\n",
    "        butte_creek_line_gdf.loc[0,\"geometry\"],\n",
    "    \"WELLINFOID\"\n",
    "    )\n",
    "    lith_logs_butte_creek_gdf.to_file(lith_logs_butte_creek_shp_path)\n",
    "\n",
    "    label_col = \"site_code\"\n",
    "\n",
    "    url = \"https://data.cnra.ca.gov/api/3/action/datastore_search_sql?\"\n",
    "    dataset_code = \"bfa9f262-24a1-45bd-8dc8-138bc8107266\"\n",
    "    site_codes_list = obs_wells_butte_creek_gdf[label_col].to_list()\n",
    "    sql_query = f'''sql=SELECT * from \"{\n",
    "    dataset_code\n",
    "    }\" WHERE \"site_code\" IN ('{ \"','\".join(site_codes_list) }')'''\n",
    "    sql_query = sql_query.replace(\" \", \"%20\")\n",
    "    sql_query = sql_query.replace('\"', \"%22\")\n",
    "    response_dmc = requests.get(url, params=sql_query)\n",
    "    response_dict = json.loads(response_dmc.text)\n",
    "\n",
    "    obs_butte_creek_df = pd.json_normalize(response_dict[\"result\"][\"records\"])\n",
    "    obs_butte_creek_df[\"date\"] = pd.to_datetime(obs_butte_creek_df[\"msmt_date\"])\n",
    "    obs_butte_creek_df = obs_butte_creek_df.sort_values(by=\"date\").reset_index(drop=True)\n",
    "    obs_butte_creek_df = pd.merge_asof(\n",
    "            obs_butte_creek_df, all_ts_df, on=\"date\", direction=\"nearest\"\n",
    "        )\n",
    "    obs_butte_creek_df = obs_butte_creek_df.drop(columns=[\"date\"])\n",
    "    obs_butte_creek_df = obs_butte_creek_df.rename(columns={\n",
    "        \"date_sim\": \"date\"})\n",
    "    # Let's average by well and date\n",
    "    obs_butte_creek_df[\"gwe\"] = obs_butte_creek_df[\"gwe\"].astype(float)\n",
    "    obs_butte_creek_df = obs_butte_creek_df[[label_col,\"date\",\"gwe\"]].groupby(\n",
    "        [label_col, \"date\"]\n",
    "    ).mean().reset_index()\n",
    "    obs_butte_creek_df.to_csv(obs_butte_creek_csv_path, index=False)\n",
    "else:\n",
    "    obs_wells_butte_creek_gdf = gpd.read_file(obs_wells_butte_creek_shp_path)\n",
    "    lith_logs_butte_creek_gdf = gpd.read_file(lith_logs_butte_creek_shp_path)\n",
    "    obs_butte_creek_df = pd.read_csv(obs_butte_creek_csv_path)\n",
    "\n",
    "\n",
    "\n",
    "# Let's get lithologies now\n",
    "lith_csv_path = os.path.join(aem_dir, \"AEM_WELL_LITHOLOGY_csv_WO7_20230327_HQonly.csv\")\n",
    "butte_lith_csv_path = os.path.join(data_dir, \"butte_creek_lithology.csv\")\n",
    "\n",
    "make_butte_lithology = False\n",
    "if make_butte_lithology:\n",
    "    lith_df = pd.read_csv(lith_csv_path)\n",
    "\n",
    "    lith_df = lith_df.rename(columns={\"WELL_INFO_ID\": \"WELLINFOID\"})\n",
    "\n",
    "    lith_df[\"GROUND_SURFACE_ELEVATION_ft\"] = lith_df[\"GROUND_SURFACE_ELEVATION_m\"] * 3.28084\n",
    "    lith_df[\"LITH_TOP_DEPTH_ft\"] = lith_df[\"LITH_TOP_DEPTH_m\"] * 3.28084\n",
    "    lith_df[\"LITH_BOT_DEPTH_ft\"] = lith_df[\"LITH_BOT_DEPTH_m\"] * 3.28084\n",
    "\n",
    "    # Let's select only the lithologies for Butte Creek\n",
    "    lith_butte_creek_df = pd.merge(\n",
    "        lith_df,\n",
    "        lith_logs_butte_creek_gdf[\"WELLINFOID\"],\n",
    "        how=\"right\",\n",
    "    ).reset_index(drop=True)\n",
    "    lith_butte_creek_df.to_csv(butte_lith_csv_path, index=False)\n",
    "else:\n",
    "    lith_butte_creek_df = pd.read_csv(butte_lith_csv_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "editable,slideshow,tags,-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
