{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f25895",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import rasterio\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "from myst_nb import glue\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "from matplotlib_map_utils.core.north_arrow import NorthArrow, north_arrow\n",
    "import numpy as np\n",
    "from shapely import LineString, Point\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from iwfm_lwa import (skip_until_flag, get_groundwater_nodes, load_gwalloutfl, get_stratigraphy, get_stream_nodes,\n",
    "                      get_var, line_to_list)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Path to the root of the repository\n",
    "repo_dir = os.getcwd()\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "while os.path.split(os.path.split(repo_dir)[0])[1] == \"c2vsim_fg_stream_transects\":\n",
    "    repo_dir = os.path.split(repo_dir)[0]\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "from functions.make_stream_lines_gdf import make_stream_lines_gdf\n",
    "from functions.project_points_gdf_to_line_string import project_points_gdf_to_line_string\n",
    "\n",
    "os.chdir(current_dir)\n",
    "\n",
    "# Let's set key paths\n",
    "data_dir = os.path.join(repo_dir, \"data\")\n",
    "model_dir = os.path.join(data_dir, \"c2vsimfg_v1.5\")\n",
    "preprocessor_dir = os.path.join(model_dir, \"Preprocessor\")\n",
    "results_dir = os.path.join(model_dir, \"Results\")\n",
    "aem_dir = os.path.join(data_dir, \"sa7_supportingdata_20230428\")\n",
    "\n",
    "gwalloutfl_path = os.path.join(results_dir, \"C2VSimFG_GW_HeadAll.out\")\n",
    "bathymetry_path = os.path.join(data_dir, \"sacramento_river_bathymetry_2m.tif\")\n",
    "sacramento_path = os.path.join(data_dir, \"sacramento.shp\")\n",
    "yuba_city_path = os.path.join(data_dir, \"yuba_city.shp\")\n",
    "chico_path = os.path.join(data_dir, \"chico.shp\")\n",
    "red_bluff_path = os.path.join(data_dir, \"red_bluff.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4e39b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# Methods\n",
    "- Description of the tools and techniques used to solve the problem stated in the introduction\n",
    "- Section check:\n",
    "  - Does it allow the reader to follow and repeat what was done?\n",
    "  - Does it permit evaluation of how skillfully the work was designed and carried out?\n",
    "  - Does it place the work in a certain historical context leaving the door open for fertile restudy as the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba029e5b",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Let's add stream coordinates to stream nodes\n",
    "# Let's create the geodataframe of streams\n",
    "\n",
    "# Path to stream definition file\n",
    "streams_def_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_StreamsSpec.dat\")\n",
    "\n",
    "# Path to node definition file\n",
    "nodes_def_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_Nodes.dat\")\n",
    "\n",
    "stream_lines_shp_path = os.path.join(data_dir, \"stream_lines.shp\")\n",
    "\n",
    "#Buffer Distance in meters\n",
    "buffer_distance_m = 500\n",
    "\n",
    "stream_nodes_df = get_stream_nodes(streams_def_file_path, rating_points=10)\n",
    "\n",
    "# We'll have to import the node definition file\n",
    "gw_nodes_df = get_groundwater_nodes(nodes_def_file_path)\n",
    "\n",
    "make_stream_lines_shp = False\n",
    "\n",
    "if make_stream_lines_shp:\n",
    "\n",
    "    streams_gdf = make_stream_lines_gdf(stream_nodes_df, gw_nodes_df)\n",
    "    streams_gdf.to_file(stream_lines_shp_path)\n",
    "\n",
    "else:\n",
    "    streams_gdf = gpd.read_file(stream_lines_shp_path)\n",
    "\n",
    "# Stream we will look at\n",
    "stream_name = \"SACRAMENTO\"\n",
    "\n",
    "stream_line_gdf = streams_gdf.loc[streams_gdf[\"name\"]==stream_name].reset_index(drop=True)\n",
    "\n",
    "stream_line_gdf = stream_line_gdf.drop(columns=\"id\")\n",
    "\n",
    "stream_line_gdf = stream_line_gdf.dissolve(by=\"name\").reset_index()\n",
    "stream_nodes_df = pd.merge(stream_nodes_df, gw_nodes_df, on=\"igw\", how=\"left\")\n",
    "\n",
    "records = []\n",
    "\n",
    "stream_line_geometry = stream_line_gdf.loc[0,\"geometry\"]\n",
    "\n",
    "stream_nodes_df = stream_nodes_df[stream_nodes_df[\"name\"] == stream_name].reset_index(drop=True)\n",
    "\n",
    "for stream_node in stream_nodes_df.itertuples():\n",
    "    stream_node_x = getattr(stream_node, \"x\")\n",
    "    stream_node_y = getattr(stream_node, \"y\")\n",
    "    irv = getattr(stream_node, \"irv\")\n",
    "    point = Point(stream_node_x, stream_node_y)\n",
    "    proj = stream_line_geometry.project(point)\n",
    "    record = {\n",
    "        \"irv\": irv,\n",
    "        \"proj\": proj\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "projs_df = pd.DataFrame(records)\n",
    "stream_nodes_df = pd.merge(stream_nodes_df, projs_df, how=\"left\")\n",
    "\n",
    "def add_point_geometry(x):\n",
    "    geometry = Point(x[\"x\"], x[\"y\"])\n",
    "    return geometry\n",
    "\n",
    "stream_nodes_df[\"geometry\"] = stream_nodes_df.apply(add_point_geometry, axis=1)\n",
    "\n",
    "save_stream_nodes = False\n",
    "stream_nodes_csv_path = os.path.join(data_dir, f\"{stream_name.lower()}_stream_nodes.csv\")\n",
    "stream_nodes_shp_path = os.path.join(data_dir, f\"{stream_name.lower()}_stream_nodes.shp\")\n",
    "if save_stream_nodes:\n",
    "    stream_nodes_gdf = gpd.GeoDataFrame(\n",
    "        stream_nodes_df,\n",
    "        geometry=stream_nodes_df.geometry,\n",
    "        crs=26910\n",
    "    )\n",
    "    values = []\n",
    "    with rasterio.open(bathymetry_path) as ds:\n",
    "        vals_array = ds.read(1)\n",
    "        for point in stream_nodes_gdf[\"geometry\"]:\n",
    "            x = point.x\n",
    "            y = point.y\n",
    "            row,col = ds.index(x,y)\n",
    "            if (row>=0) & (row<vals_array.shape[0]) & (col>=0) & (col<vals_array.shape[1]):\n",
    "                value = vals_array[row,col]\n",
    "            else:\n",
    "                value = np.nan\n",
    "            values.append(value)\n",
    "    # let's remove 0s, which QGIS used to represent nas\n",
    "    values = [val if val != 0 else np.nan for val in values]\n",
    "    # Let's convert from m to ft\n",
    "    values = [val * 3.28084 if not np.isnan(val) else np.nan for val in values]\n",
    "    # Let's add bathymetry values to stream nodes\n",
    "    stream_nodes_gdf[\"bathymetry_ft\"] = values\n",
    "    stream_nodes_df[\"bathymetry_ft\"] = values\n",
    "\n",
    "    stream_nodes_df.to_csv(stream_nodes_csv_path, index=False)\n",
    "    stream_nodes_gdf.to_file(stream_nodes_shp_path)\n",
    "else:\n",
    "    stream_nodes_df = pd.read_csv(stream_nodes_csv_path)\n",
    "    stream_nodes_gdf = gpd.read_file(stream_nodes_shp_path)\n",
    "\n",
    "\n",
    "# Let's load stratigraphy file into dataframe\n",
    "stratigraphy_file_path = os.path.join(preprocessor_dir, \"C2VSimFG_Stratigraphy.dat\")\n",
    "\n",
    "\n",
    "stratigraphy_df = get_stratigraphy(stratigraphy_file_path)\n",
    "\n",
    "wt_stream_nodes_csv_path = os.path.join(data_dir, f\"{stream_name.lower()}_gwallout_stream_nodes.csv\")\n",
    "\n",
    "make_wt_stream_nodes = False\n",
    "if make_wt_stream_nodes:\n",
    "\n",
    "    gwallout_df = load_gwalloutfl(gwalloutfl_path)\n",
    "    # Let's convert heads from m to ft\n",
    "\n",
    "    gwallout_df_long = pd.melt(gwallout_df, id_vars=[\"date\", \"layer\"], var_name=\"igw\", value_name=\"head_ft\")\n",
    "\n",
    "    gwallout_df = None\n",
    "\n",
    "    # Let's add bottom elevations of layers\n",
    "    stratigraphy_df[\"botm_lay_1\"] = stratigraphy_df[\"gse\"] - stratigraphy_df[\"thck_lay_1\"]\n",
    "\n",
    "    nlay = 4\n",
    "\n",
    "    for lay in range(2, nlay+1):\n",
    "        stratigraphy_df[f\"botm_lay_{lay}\"] = stratigraphy_df[f\"botm_lay_{lay-1}\"] - stratigraphy_df[f\"thck_lay_{lay}\"]\n",
    "\n",
    "    gwallout_df_wide = pd.pivot(gwallout_df_long,index=[\"date\", \"igw\"], columns=[\"layer\"], values=[\"head_ft\"])\n",
    "\n",
    "    gwallout_df_long = None\n",
    "\n",
    "    gwallout_df_wide = gwallout_df_wide.reset_index()\n",
    "\n",
    "    colnames = gwallout_df_wide.columns\n",
    "\n",
    "    colnames = [name[0]+\"_\"+str(name[1]) if len(str(name[1]))>0 else name[0] for name in colnames ]\n",
    "\n",
    "    gwallout_df_wide.columns = colnames\n",
    "\n",
    "    gwallout_df_wide = pd.merge(\n",
    "        gwallout_df_wide,\n",
    "    stratigraphy_df[\n",
    "        [\n",
    "            \"igw\", \"gse\"\n",
    "        ] + [\n",
    "            col for col in stratigraphy_df.columns if \"botm\" in col\n",
    "        ] + [\n",
    "            col for col in stratigraphy_df.columns if \"thck_lay\" in col\n",
    "        ]\n",
    "    ],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    def get_wte(x):\n",
    "        gse = x[\"gse\"]\n",
    "        wte = x[\"head_ft_1\"]\n",
    "        lay = 1\n",
    "        botm = x[\"botm_lay_1\"]\n",
    "        thck = x[\"thck_lay_1\"]\n",
    "        while ((\n",
    "                wte >= gse\n",
    "        ) | (\n",
    "                wte <= botm\n",
    "        ) | (\n",
    "                thck == 0\n",
    "        ))& (\n",
    "            lay < nlay\n",
    "        ):\n",
    "            lay = lay+1\n",
    "            wte = x[f\"head_ft_{lay}\"]\n",
    "            botm = x[f\"botm_lay_{lay}\"]\n",
    "            thck = x[f\"thck_lay_{lay}\"]\n",
    "        return wte\n",
    "\n",
    "    gwallout_stream_nodes_df = pd.merge(\n",
    "        gwallout_df_wide,\n",
    "        stream_nodes_df[\"igw\"],\n",
    "        how=\"right\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    gwallout_df_wide = None\n",
    "\n",
    "    gwallout_stream_nodes_df[\"wte_ft\"] = gwallout_stream_nodes_df.apply(get_wte, axis=1)\n",
    "\n",
    "    gwallout_stream_nodes_df = gwallout_stream_nodes_df[\n",
    "        [\"date\", \"igw\", \"wte_ft\", \"head_ft_1\", \"head_ft_2\", \"head_ft_2\", \"head_ft_3\", \"head_ft_4\"]\n",
    "    ]\n",
    "    gwallout_stream_nodes_df = pd.merge(\n",
    "        gwallout_stream_nodes_df,\n",
    "        stream_nodes_df[\"igw\"],\n",
    "\n",
    "        how=\"right\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    gwallout_stream_nodes_df.to_csv(wt_stream_nodes_csv_path, index=False)\n",
    "else:\n",
    "    gwallout_stream_nodes_df = pd.read_csv(wt_stream_nodes_csv_path)\n",
    "\n",
    "\n",
    "all_ts_df = pd.DataFrame(\n",
    "    {\"date\": pd.to_datetime(gwallout_stream_nodes_df[\"date\"].unique())}\n",
    "\n",
    ")\n",
    "\n",
    "all_ts_df[\"date_sim\"] = all_ts_df[\"date\"]\n",
    "buffer = stream_line_gdf.buffer(buffer_distance_m)[0]\n",
    "obs_wells_shp_path = os.path.join(data_dir, f\"obs_wells_{stream_name.lower()}.shp\")\n",
    "lith_logs_shp_path = os.path.join(data_dir, f\"lith_logs_{stream_name.lower()}.shp\")\n",
    "obs_csv_path = os.path.join(data_dir, f\"obs_wells_{stream_name.lower()}.csv\")\n",
    "\n",
    "select_casgem_wells_and_lithology_logs = True\n",
    "if select_casgem_wells_and_lithology_logs:\n",
    "    # We download CASGEM wells for the counties that Butte Creek crosses\n",
    "    url = \"https://data.cnra.ca.gov/api/3/action/datastore_search_sql?\"\n",
    "    records = []\n",
    "    for county in ['Butte', 'Colusa', 'Glenn', 'Sacramento', 'Shasta','Sutter', 'Tehama', 'Yolo']:\n",
    "        sql_county = f'''sql=SELECT * from \"af157380-fb42-4abf-b72a-6f9f98868077\" WHERE \"county_name\" IN ('{county}')'''\n",
    "        sql_county = sql_county.replace(\" \", \"%20\")\n",
    "        sql_county = sql_county.replace('\"', \"%22\")\n",
    "        response_dmc = requests.get(url, params=sql_county)\n",
    "\n",
    "        response_dict = json.loads(response_dmc.text)\n",
    "        records += response_dict[\"result\"][\"records\"]\n",
    "\n",
    "    obs_wells_df = pd.json_normalize(records)\n",
    "    def add_geom_points(x):\n",
    "        geometry = Point(x[\"longitude\"], x[\"latitude\"])\n",
    "        return geometry\n",
    "\n",
    "    obs_wells_df[\"geometry\"] = obs_wells_df.apply(add_geom_points, axis=1)\n",
    "    obs_wells_gdf = gpd.GeoDataFrame(obs_wells_df, geometry=obs_wells_df.geometry, crs=4326)\n",
    "\n",
    "    obs_wells_gdf = obs_wells_gdf.to_crs(streams_gdf.crs)\n",
    "\n",
    "    obs_wells_gdf = obs_wells_gdf.loc[obs_wells_gdf.geometry.within(buffer)].reset_index(drop=True)\n",
    "\n",
    "    # Let's project the wells to the Sacramento River line\n",
    "    obs_wells_gdf = project_points_gdf_to_line_string(\n",
    "        obs_wells_gdf,\n",
    "        stream_line_gdf.loc[0,\"geometry\"],\n",
    "    \"site_code\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    lith_logs_shp_path_in = os.path.join(aem_dir, \"WO7_HQ_LithologyWells.shp\")\n",
    "\n",
    "    lith_logs_shp_path_in_sa6 = os.path.join(aem_dir, \"WO6_HQ_LithologyWells.shp\")\n",
    "\n",
    "    lith_logs_gdf = gpd.read_file(lith_logs_shp_path_in)\n",
    "    lith_logs_gdf = lith_logs_gdf.to_crs(streams_gdf.crs)\n",
    "    lith_logs_sa6_gdf = gpd.read_file(lith_logs_shp_path_in_sa6)\n",
    "    lith_logs_sa6_gdf = lith_logs_sa6_gdf.to_crs(streams_gdf.crs)\n",
    "\n",
    "    lith_logs_gdf = pd.concat(\n",
    "        [\n",
    "            lith_logs_gdf,\n",
    "            lith_logs_sa6_gdf\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    lith_logs_gdf = lith_logs_gdf.loc[lith_logs_gdf.geometry.within(buffer)].reset_index(drop=True)\n",
    "\n",
    "    # Let's project the lithology logs to the Butte Creek line\n",
    "    lith_logs_gdf = project_points_gdf_to_line_string(\n",
    "        lith_logs_gdf,\n",
    "        stream_line_gdf.loc[0,\"geometry\"],\n",
    "    \"WELLINFOID\"\n",
    "    )\n",
    "    lith_logs_gdf.to_file(lith_logs_shp_path)\n",
    "\n",
    "    label_col = \"site_code\"\n",
    "\n",
    "    url = \"https://data.cnra.ca.gov/api/3/action/datastore_search_sql?\"\n",
    "    dataset_code = \"bfa9f262-24a1-45bd-8dc8-138bc8107266\"\n",
    "    site_codes_list = obs_wells_gdf[label_col].to_list()\n",
    "    records = []\n",
    "    for site_code in site_codes_list:\n",
    "        sql_query = f'''sql=SELECT * from \"{\n",
    "        dataset_code\n",
    "        }\" WHERE \"site_code\" IN ('{site_code}')'''\n",
    "        sql_query = sql_query.replace(\" \", \"%20\")\n",
    "        sql_query = sql_query.replace('\"', \"%22\")\n",
    "        response_dmc = requests.get(url, params=sql_query)\n",
    "        response_dict = json.loads(response_dmc.text)\n",
    "        records += response_dict[\"result\"][\"records\"]\n",
    "\n",
    "    obs_df = pd.json_normalize(records)\n",
    "    obs_df[\"date\"] = pd.to_datetime(obs_df[\"msmt_date\"])\n",
    "    obs_df = obs_df.sort_values(by=\"date\").reset_index(drop=True)\n",
    "    obs_df = pd.merge_asof(\n",
    "            obs_df, all_ts_df, on=\"date\", direction=\"nearest\"\n",
    "        )\n",
    "    obs_df = obs_df.drop(columns=[\"date\"])\n",
    "    obs_df = obs_df.rename(columns={\n",
    "        \"date_sim\": \"date\"})\n",
    "    # Let's average by well and date\n",
    "    obs_df[\"gwe\"] = obs_df[\"gwe\"].astype(float)\n",
    "    obs_df = obs_df[[label_col,\"date\",\"gwe\"]].groupby(\n",
    "        [label_col, \"date\"]\n",
    "    ).mean().reset_index()\n",
    "    obs_df = obs_df.loc[\n",
    "        (\n",
    "                obs_df[\"date\"] >= pd.to_datetime(\"1973-09-01\")\n",
    "        ) & (obs_df[\"date\"] <= pd.to_datetime(\"2021-09-30\"))\n",
    "        ].reset_index(drop=True)\n",
    "    obs_df.to_csv(obs_csv_path, index=False)\n",
    "\n",
    "    obs_wells_gdf = obs_wells_gdf.loc[\n",
    "        obs_wells_gdf[\"site_code\"].isin(obs_df[\"site_code\"])\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    obs_wells_gdf.to_file(obs_wells_shp_path)\n",
    "else:\n",
    "    obs_wells_gdf = gpd.read_file(obs_wells_shp_path)\n",
    "    lith_logs_gdf = gpd.read_file(lith_logs_shp_path)\n",
    "    obs_df = pd.read_csv(obs_csv_path)\n",
    "\n",
    "\n",
    "\n",
    "# Let's get lithologies now\n",
    "lith_csv_in_path = os.path.join(aem_dir, \"AEM_WELL_LITHOLOGY_csv_WO7_20230327_HQonly.csv\")\n",
    "lith_csv_in_path_6 = os.path.join(aem_dir, \"AEM_WELL_LITHOLOGY_csv_WO6_20230103_HQonly.csv\")\n",
    "lith_csv_path = os.path.join(data_dir, f\"{stream_name.lower()}_lithology.csv\")\n",
    "\n",
    "make_lithology = False\n",
    "if make_lithology:\n",
    "    lith_df = pd.read_csv(lith_csv_in_path)\n",
    "\n",
    "    lith_df_6 = pd.read_csv(lith_csv_in_path_6)\n",
    "\n",
    "    lith_df = pd.concat(\n",
    "        [\n",
    "            lith_df,\n",
    "            lith_df_6\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    lith_df = lith_df.rename(columns={\"WELL_INFO_ID\": \"WELLINFOID\"})\n",
    "\n",
    "    lith_df[\"GROUND_SURFACE_ELEVATION_ft\"] = lith_df[\"GROUND_SURFACE_ELEVATION_m\"] * 3.28084\n",
    "    lith_df[\"LITH_TOP_DEPTH_ft\"] = lith_df[\"LITH_TOP_DEPTH_m\"] * 3.28084\n",
    "    lith_df[\"LITH_BOT_DEPTH_ft\"] = lith_df[\"LITH_BOT_DEPTH_m\"] * 3.28084\n",
    "\n",
    "    # Let's select only the lithologies for Butte Creek\n",
    "    lith_df = pd.merge(\n",
    "        lith_df,\n",
    "        lith_logs_gdf[\"WELLINFOID\"],\n",
    "        how=\"right\",\n",
    "    ).reset_index(drop=True)\n",
    "    lith_df.to_csv(lith_csv_path, index=False)\n",
    "else:\n",
    "    lith_df = pd.read_csv(lith_csv_path)\n",
    "\n",
    "# We get the axis limits so that all the points in the cross section are shown in the map\n",
    "\n",
    "stream_line_string = stream_line_gdf.loc[0,\"geometry\"]\n",
    "\n",
    "# Let's get the limits of the map\n",
    "xsec_start = stream_line_string.length\n",
    "xsec_end = 0\n",
    "\n",
    "# Coordinates associated with the start and end of the cross section\n",
    "xsec_start_coords = list(stream_line_string.interpolate(xsec_start).coords)[0]\n",
    "xsec_end_coords = list(stream_line_string.interpolate(xsec_end).coords)[0]\n",
    "\n",
    "x_min = xsec_start_coords[0]\n",
    "x_max = xsec_end_coords[0]\n",
    "y_min = xsec_start_coords[1]\n",
    "y_max = xsec_end_coords[1]\n",
    "\n",
    "\n",
    "for row in stream_nodes_gdf.itertuples():\n",
    "    geometry = getattr(row, \"geometry\")\n",
    "    point = geometry.coords[0]\n",
    "    proj_d = stream_line_string.project(geometry)\n",
    "    # We only consider points within the start and end of the cross section\n",
    "    if (proj_d <= xsec_start) & (proj_d >= xsec_end):\n",
    "        if point[0] < x_min:\n",
    "            x_min = point[0]\n",
    "        if point[0] > x_max:\n",
    "            x_max = point[0]\n",
    "        if point[1] < y_min:\n",
    "            y_min = point[1]\n",
    "        if point[1] > y_max:\n",
    "            y_max = point[1]\n",
    "\n",
    "# We set an offset of 500 m for axes limits\n",
    "axis_lims_offset = 5000\n",
    "\n",
    "step_miles_x = np.power(\n",
    "    10, np.modf\n",
    "            (np.log10(\n",
    "            (\n",
    "                    x_max - x_min\n",
    "            ) / 1609.34\n",
    "        )\n",
    "        )[1]\n",
    ")\n",
    "\n",
    "xlims_utm10n_gdf = gpd.GeoDataFrame(\n",
    "    {\"utm_10N\": [x_min-axis_lims_offset, x_max+axis_lims_offset]},\n",
    "    geometry=[Point(x_min-axis_lims_offset, y_min), Point(x_max+axis_lims_offset, y_min)],\n",
    "    crs=26910\n",
    ")\n",
    "\n",
    "ylims_utm10n_gdf = gpd.GeoDataFrame(\n",
    "    {\"utm_10N\": [y_min-axis_lims_offset, y_max+axis_lims_offset]},\n",
    "    geometry=[Point(x_min, y_min-axis_lims_offset), Point(x_min, y_max+axis_lims_offset)],\n",
    "    crs=26910\n",
    ")\n",
    "\n",
    "\n",
    "# Let's convert to geographic coordinates\n",
    "xlims_geographic_gdf = xlims_utm10n_gdf.to_crs(4326)\n",
    "x_max_degrees = xlims_geographic_gdf.loc[1, \"geometry\"].x\n",
    "x_min_degrees = xlims_geographic_gdf.loc[0, \"geometry\"].x\n",
    "\n",
    "ylims_geographic_gdf = ylims_utm10n_gdf.to_crs(4326)\n",
    "y_max_degrees = ylims_geographic_gdf.loc[1, \"geometry\"].y\n",
    "y_min_degrees = ylims_geographic_gdf.loc[0, \"geometry\"].y\n",
    "\n",
    "step_degrees_x = np.modf(x_max_degrees - x_min_degrees)[1]/4\n",
    "\n",
    "step_degrees_y = np.modf(y_max_degrees - y_min_degrees)[1]/4\n",
    "\n",
    "xticks = np.arange(\n",
    "            np.modf(x_min_degrees/step_degrees_x)[1]*step_degrees_x,\n",
    "            np.modf(x_max_degrees/step_degrees_x)[1]*step_degrees_x,\n",
    "            step_degrees_x)\n",
    "\n",
    "yticks = np.arange(\n",
    "            np.modf(y_min_degrees/step_degrees_y)[1]*step_degrees_y,\n",
    "            np.modf(y_max_degrees/step_degrees_y)[1]*step_degrees_y,\n",
    "            step_degrees_y)\n",
    "\n",
    "xticks_labels = [f\"{np.abs(np.modf(tick)[1]):.0f}°{np.modf(np.modf(tick)[0]*60)[1]:.0f}'{np.modf(np.modf(tick)[0]*60)[0]*3600:.1f}\\\" W\" for tick in xticks]\n",
    "\n",
    "yticks_labels = [f\"{np.modf(tick)[1]:.0f}°{np.modf(np.modf(tick)[0]*60)[1]:.0f}'{np.modf(np.modf(tick)[0]*60)[0]*3600:.1f}\\\" N\" for tick in yticks]\n",
    "\n",
    "step_miles_y = np.power(\n",
    "    5, np.modf\n",
    "            (np.log10(\n",
    "            (\n",
    "                    y_max - y_min\n",
    "            ) / 1609.34\n",
    "        )\n",
    "        )[1]\n",
    ")\n",
    "\n",
    "xticks_gdf = gpd.GeoDataFrame(\n",
    "    {\"4326\": xticks},\n",
    "    geometry=[Point(x, xlims_geographic_gdf.loc[0, \"geometry\"].y) for x in xticks],\n",
    "    crs=4326\n",
    ")\n",
    "\n",
    "yticks_gdf = gpd.GeoDataFrame(\n",
    "    {\"4326\": yticks},\n",
    "    geometry=[Point(ylims_geographic_gdf.loc[0, \"geometry\"].x, y) for y in yticks],\n",
    "    crs=4326\n",
    ")\n",
    "\n",
    "xticks_gdf = xticks_gdf.to_crs(26910)\n",
    "\n",
    "yticks_gdf = yticks_gdf.to_crs(26910)\n",
    "\n",
    "xticks_gdf[\"x\"] = xticks_gdf[\"geometry\"].x\n",
    "\n",
    "yticks_gdf[\"y\"] = yticks_gdf[\"geometry\"].y\n",
    "\n",
    "# We will create a geodataframe with the tickmarks, which we will project to EPSG:4326\n",
    "# the tickmarks in geographic coordinates\n",
    "\n",
    "sacramento_gdf = gpd.read_file(sacramento_path)\n",
    "yuba_city_gdf = gpd.read_file(yuba_city_path)\n",
    "chico_gdf = gpd.read_file(chico_path)\n",
    "red_bluff_gdf = gpd.read_file(red_bluff_path)\n",
    "\n",
    "# Let's make geodataframe with transects postmiles\n",
    "postmiles = [50, 100, 161, 231]\n",
    "\n",
    "# Convert to distance from confluence with San Joaquin\n",
    "postmiles_text = [int(np.modf((stream_line_string.length/1609.34-postmile)/10)[1]*10) for postmile in postmiles]\n",
    "\n",
    "postmiles_pts = [stream_line_string.interpolate(postmile*1609.34) for postmile in postmiles]\n",
    "\n",
    "postmiles_gdf = gpd.GeoDataFrame(\n",
    "    data={\"postmile\": postmiles_text,\n",
    "          \"geometry\": postmiles_pts},\n",
    "    crs=26910\n",
    ")\n",
    "\n",
    "subplot_kwargs = {\"ncols\": 2,\n",
    "                  \"width_ratios\": [0.9, 0.1],\n",
    "                  \"figsize\": (6, 8)}\n",
    "\n",
    "fig, axes = plt.subplots(**subplot_kwargs)\n",
    "\n",
    "# Let's plot the Sacramento River stream line now\n",
    "\n",
    "stream_line_style_kwargs = {\"lw\": 2}\n",
    "legend_elements = []\n",
    "\n",
    "axes[0] = stream_line_gdf.plot(ax=axes[0], color=\"blue\", **stream_line_style_kwargs)\n",
    "legend_elements.append(\n",
    "    Line2D([0], [0], color=\"blue\", label= \"Sacramento River\", zorder = 1, **stream_line_style_kwargs)\n",
    ")\n",
    "\n",
    "# Let's plot the CASGEM wells now\n",
    "casgem_well_style_kwargs = {}\n",
    "legend_elements.append(Line2D([0], [0], label='CASGEM Wells',\n",
    "                              markerfacecolor=\"#CB6015\",marker=\"o\",\n",
    "                              color='w', markersize=10, **casgem_well_style_kwargs))\n",
    "axes[0] = obs_wells_gdf.plot(ax=axes[0], color = \"#CB6015\", zorder = 2, **casgem_well_style_kwargs)\n",
    "\n",
    "axes[1].set_axis_off()\n",
    "\n",
    "# Let's plot the lithology logs now\n",
    "lithology_log_style_kwargs = {\"marker\": \"^\"}\n",
    "axes[0] = lith_logs_gdf.plot(ax=axes[0], color = \"#9BAA4B\", zorder = 2, **lithology_log_style_kwargs)\n",
    "\n",
    "legend_elements.append(Line2D([0], [0], label='Lithology Logs',\n",
    "                              markerfacecolor=\"#9BAA4B\",\n",
    "                              color='w', markersize=10, **lithology_log_style_kwargs))\n",
    "\n",
    "axes[0] = sacramento_gdf.plot(ax=axes[0], color = 'none',  hatch = \"////\", edgecolor=\"#555555\")\n",
    "legend_elements.append(Patch(facecolor=\"none\", hatch = \"////\", edgecolor=\"#555555\", label=\"Sacramento\"))\n",
    "\n",
    "axes[0] = yuba_city_gdf.plot(ax=axes[0], color = 'none',  hatch = \"\\\\\\\\\\\\\\\\\", edgecolor=\"#F6B704\")\n",
    "legend_elements.append(Patch(facecolor=\"none\", hatch = \"\\\\\\\\\\\\\\\\\", edgecolor=\"#F6B704\", label=\"Yuba City\"))\n",
    "\n",
    "axes[0] = chico_gdf.plot(ax=axes[0], color = 'none',  hatch = \"----\", edgecolor=\"#4B7164\")\n",
    "legend_elements.append(Patch(facecolor=\"none\",  hatch = \"----\", edgecolor=\"#4B7164\", label=\"Chico\"))\n",
    "\n",
    "axes[0] = red_bluff_gdf.plot(ax=axes[0], color = 'none',  hatch = \"||||\", edgecolor=\"#A2495E\")\n",
    "legend_elements.append(Patch(facecolor=\"none\",  hatch = \"||||\", edgecolor=\"#A2495E\", label=\"Red Bluff\"))\n",
    "\n",
    "axes[1].legend(handles=legend_elements)\n",
    "\n",
    "axes[0].set_xlim(x_min-axis_lims_offset, x_max+axis_lims_offset)\n",
    "axes[0].set_ylim(y_min-axis_lims_offset, y_max+axis_lims_offset)\n",
    "\n",
    "axes[0].set_xticks(xticks_gdf[\"x\"], labels=xticks_labels, rotation=90)\n",
    "axes[0].set_yticks(yticks_gdf[\"y\"], labels=yticks_labels)\n",
    "\n",
    "asb = AnchoredSizeBar(axes[0].transData,\n",
    "                      5*1609.34,\n",
    "                      \"5 mi\",\n",
    "                      size_vertical=1609.34,\n",
    "                      loc=\"upper right\",\n",
    "                      pad=0.1,\n",
    "                      borderpad=0.5,\n",
    "                      sep=5,\n",
    "                      frameon=False)\n",
    "axes[0].add_artist(asb)\n",
    "north_arrow(\n",
    "    axes[0], location=\"lower left\", rotation={\"crs\": stream_line_gdf.crs, \"reference\": \"center\"}\n",
    ")\n",
    "\n",
    "postmile_240 = postmiles_gdf.loc[0, \"postmile\"]\n",
    "geom_pm_240 = postmiles_gdf.loc[0, \"geometry\"]\n",
    "xy_coords_pm_240 = list(geom_pm_240.coords)[0]\n",
    "axes[0].annotate(\n",
    "        f\"{postmile_240}\",\n",
    "        xy=xy_coords_pm_240,\n",
    "        xytext=(xy_coords_pm_240[0]+8000, xy_coords_pm_240[1]),\n",
    "        bbox=dict(boxstyle=\"square\", fc=\"w\"),\n",
    "    )\n",
    "\n",
    "postmile_190 = postmiles_gdf.loc[1, \"postmile\"]\n",
    "geom_pm_190 = postmiles_gdf.loc[1, \"geometry\"]\n",
    "xy_coords_pm_190 = list(geom_pm_190.coords)[0]\n",
    "axes[0].annotate(\n",
    "        f\"{postmile_190}\",\n",
    "        xy=xy_coords_pm_190,\n",
    "        xytext=(xy_coords_pm_190[0]-25000, xy_coords_pm_190[1]),\n",
    "        bbox=dict(boxstyle=\"square\", fc=\"w\"),\n",
    "    )\n",
    "\n",
    "postmile_120 = postmiles_gdf.loc[2, \"postmile\"]\n",
    "geom_pm_120 = postmiles_gdf.loc[2, \"geometry\"]\n",
    "xy_coords_pm_120 = list(geom_pm_120.coords)[0]\n",
    "axes[0].annotate(\n",
    "        f\"{postmile_120}\",\n",
    "        xy=xy_coords_pm_120,\n",
    "        xytext=(xy_coords_pm_120[0]-25000, xy_coords_pm_120[1]),\n",
    "        bbox=dict(boxstyle=\"square\", fc=\"w\"),\n",
    "    )\n",
    "\n",
    "postmile_60 = postmiles_gdf.loc[3, \"postmile\"]\n",
    "geom_pm_60 = postmiles_gdf.loc[3, \"geometry\"]\n",
    "xy_coords_pm_60 = list(geom_pm_60.coords)[0]\n",
    "axes[0].annotate(\n",
    "        f\"{postmile_60}\",\n",
    "        xy=xy_coords_pm_60,\n",
    "        xytext=(xy_coords_pm_60[0]-25000, xy_coords_pm_60[1]),\n",
    "        bbox=dict(boxstyle=\"square\", fc=\"w\"),\n",
    "    )\n",
    "\n",
    "# for row in postmiles_gdf.itertuples():\n",
    "#     postmile = getattr(row, \"postmile\")\n",
    "#     geom = getattr(row, \"geometry\")\n",
    "#     axes[0].annotate(\n",
    "#         f\"{postmile}\",\n",
    "#         xy=list(geom.coords)[0],\n",
    "#         xytext=list(geom.coords)[0],\n",
    "#         bbox=dict(boxstyle=\"square\", fc=\"w\"),\n",
    "#     )\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "glue(\"sac_river_fig\", fig, display=False)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de513bf",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```{glue:figure} sac_river_fig\n",
    ":figwidth: 800px\n",
    ":name: \"sac_river_fig\"\n",
    "\n",
    "Sacramento River and selected CASGEM wells and lithology logs.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ba58f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "editable,slideshow,tags,-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
